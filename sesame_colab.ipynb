{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This Is A Demo For Sesame CSM (Coherent Speech Models)\n",
        "*Created by: Chaitanya Benade | [Website](https://chaitanya-benade.space/)*\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "**Very Important:** Create a notebook secret with name of `HF_TOKEN` and value of your Hugging Face token.\n",
        "[Get your token here](https://huggingface.co/docs/hub/en/security-tokens)\n",
        "\n",
        "### Initial Setup"
      ],
      "metadata": {
        "id": "SpM1i_yscurp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VHGScYLCFi0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/SesameAILabs/csm.git\n",
        "%cd csm\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick Start Example\n",
        "\n",
        "### This is a basic simple code to verify everything is working correctly (basically what sesame provides) . Make Sure this runs successfully without any erros. if this runs then everything will"
      ],
      "metadata": {
        "id": "5fBifomri-Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from generator import load_csm_1b\n",
        "import torchaudio\n",
        "\n",
        "model_path = hf_hub_download(repo_id=\"sesame/csm-1b\", filename=\"ckpt.pt\")\n",
        "generator = load_csm_1b(model_path, \"cuda\")\n",
        "audio = generator.generate(\n",
        "    text=\"Hello from Sesame.\",\n",
        "    speaker=0,\n",
        "    context=[],\n",
        "    max_audio_length_ms=10_000,\n",
        ")\n",
        "\n",
        "torchaudio.save(\"audio.wav\", audio.unsqueeze(0).cpu(), generator.sample_rate)\n"
      ],
      "metadata": {
        "id": "BE9vbB2iFtD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Setup for Multiple Uses\n",
        "\n",
        "This is so you Dont load the model **Every Freaking time**"
      ],
      "metadata": {
        "id": "typFwygja4zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from generator import load_csm_1b\n",
        "import torchaudio\n",
        "\n",
        "model_path = hf_hub_download(repo_id=\"sesame/csm-1b\", filename=\"ckpt.pt\")\n",
        "generator = load_csm_1b(model_path, \"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "id": "jFvJIihOGT6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Audio Generation"
      ],
      "metadata": {
        "id": "Bk0suBvyj6dE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have load the model we just have to worry about generating audio.\n",
        "\n",
        ">And To Be Honest this has a very little context window with referance and without refrance the quality is okaish so you have to give it a referance\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v-ykXrKRbLKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MUUHT5b1bWDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But first without referance. this is go 100 sec as per my testing. you can test more. you just need to change the max_audio_length_ms which is in milisecounds"
      ],
      "metadata": {
        "id": "Xt1ELXpXbXoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Generation Without Reference\n",
        "\n",
        "**Note:** This can take a long time to generate. Like really Really REALLLLYY LONG"
      ],
      "metadata": {
        "id": "8kPxM_M5djII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "audio = generator.generate(\n",
        "    text=\"\"\"\n",
        "\n",
        "   On a lonely cliffside overlooking the restless sea stood an ancient lighthouse, its white-and-red tower weathered by time and countless storms. Locals called it The Whispering Lighthouse, though no one knew exactly why. Some said that on stormy nights, when the wind howled through the rocks, you could hear whispers coming from the tower—soft, eerie voices carried by the sea breeze.\n",
        "\n",
        "No one had lived there for decades. The last keeper, old Henry Caldwell, had vanished one night without a trace. His logbook was found open on the desk, the last entry reading only:\n",
        "\n",
        "\"The light must never go out.\"\n",
        "\n",
        "For years, sailors still saw the beam cutting through the mist, even though everyone swore the lighthouse was abandoned. Some believed it was Henry’s ghost, keeping his post in the afterlife.\n",
        "\n",
        "One evening, a young journalist named Evelyn decided to investigate. Armed with a flashlight and a stubborn sense of curiosity, she hiked up to the lighthouse just as the sun dipped below the horizon. The door creaked open with surprising ease, and inside, the air smelled of salt and dust.\n",
        "\n",
        "As she climbed the spiral staircase, her footsteps echoed against the stone walls. The higher she went, the more she felt… watched. The whispers started softly at first, like a breeze through an open window. Then they grew clearer.\n",
        "\"\"\",\n",
        "    speaker=0,\n",
        "    context=[],\n",
        "    max_audio_length_ms=100_000,\n",
        ")\n",
        "\n",
        "torchaudio.save(\"audio.wav\", audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "ipd.Audio(\"audio.wav\")"
      ],
      "metadata": {
        "id": "llZC4TM0GVWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Here is a short example. this will take around 4 sec to generate without referance"
      ],
      "metadata": {
        "id": "xv5Ns4CElCGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "# Generate audio using the preloaded generator\n",
        "audio = generator.generate(\n",
        "    text=\"Hello from Sesame.\",\n",
        "    speaker=0,\n",
        "    context=[],\n",
        "    max_audio_length_ms=100_000,  # This remains unchanged as requested\n",
        ")\n",
        "\n",
        "# Save the generated audio to a file\n",
        "output_file = \"audio.wav\"\n",
        "torchaudio.save(output_file, audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "print(f\"Audio saved to {output_file}\")\n",
        "ipd.Audio(\"audio.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MKlK0NnNLm7",
        "outputId": "bc749835-7bc8-492f-d46f-e81a70dcd116"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio saved to audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced: Audio Generation with Reference"
      ],
      "metadata": {
        "id": "MViCQeFakx43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete Setup for Reference-Based Generation"
      ],
      "metadata": {
        "id": "cGtdydpUkylG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">here we load the model and make sure they are ready to generate audio with referance"
      ],
      "metadata": {
        "id": "CWvBYLK0aoLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from huggingface_hub import hf_hub_download\n",
        "from generator import load_csm_1b, Segment  # Assuming Segment is defined here\n",
        "import os\n",
        "import torchaudio\n",
        "import IPython.display as ipd\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "cache_dir = \"./cache\"\n",
        "os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "# Models will be dowloaded automatically\n",
        "model_path = hf_hub_download(repo_id=\"sesame/csm-1b\", filename=\"ckpt.pt\", cache_dir=cache_dir)\n",
        "generator = load_csm_1b(model_path, device)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Helper function to load and resample audio\n",
        "def load_audio(audio_path):\n",
        "    # Load audio; torchaudio.load returns a tensor of shape [channels, time]\n",
        "    audio_tensor, sample_rate = torchaudio.load(audio_path)\n",
        "    # Remove any extra dimensions if present (we expect [C, T])\n",
        "    if audio_tensor.dim() > 2:\n",
        "        audio_tensor = audio_tensor.squeeze(0)\n",
        "    # Resample to the generator's sample rate\n",
        "    audio_tensor = torchaudio.functional.resample(audio_tensor, orig_freq=sample_rate, new_freq=generator.sample_rate)\n",
        "    return audio_tensor\n"
      ],
      "metadata": {
        "id": "0L86h-LZKjSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### THIS IS VERY IMPORT AND THIS TOOK ME HOURS TO GET RIGHT. WHILE PLAYING SPIDER MAN 2 BUT STILL\n",
        "\n",
        "make sure to run this :)"
      ],
      "metadata": {
        "id": "Az7nzgEclRBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "\n",
        "def load_audio(audio_path, target_sample_rate):\n",
        "    # Load the audio file\n",
        "    audio_tensor, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "    # Convert to mono by averaging channels if necessary\n",
        "    if audio_tensor.size(0) == 2:  # Stereo\n",
        "        audio_tensor = audio_tensor.mean(dim=0)  # [T]\n",
        "    elif audio_tensor.size(0) > 1:  # Multi-channel (>2)\n",
        "        audio_tensor = audio_tensor[0, :]  # Take first channel, [T]\n",
        "    else:  # Already mono, [1, T]\n",
        "        audio_tensor = audio_tensor.squeeze(0)  # Remove channel dim, [T]\n",
        "\n",
        "    # Resample to the target sample rate\n",
        "    audio_tensor = torchaudio.functional.resample(\n",
        "        audio_tensor,\n",
        "        orig_freq=sample_rate,\n",
        "        new_freq=target_sample_rate\n",
        "    )\n",
        "\n",
        "    return audio_tensor"
      ],
      "metadata": {
        "id": "YFjYS6SFVzKr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example 1: Reference-Based Audio Generation\n",
        "Bring your own audio This one is tailored for one minute of audio, and I would highly encourage you to use Gemini to translate your audio."
      ],
      "metadata": {
        "id": "O103vr0yln2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the reference audio file for speaker 0\n",
        "from IPython.display import Audio\n",
        "reference_audio_path = \"/content/csm/sample.mp3\"  # Your reference audio file\n",
        "ref_audio = load_audio(reference_audio_path, generator.sample_rate)\n",
        "print(\"Reference audio shape after loading:\", ref_audio.shape)  # Should print [120050]\n",
        "\n",
        "# Create segment with audio=[T]\n",
        "ref_segment = Segment(\n",
        "    text=\"Well, hello again. Looks like we have another chance to chat before life gets in the way. Where were we? Oh, testing, huh? Sounds intriguing. But remember, I'm just a friendly AI. Here to have a good conversation, not get into any trouble. What kind of test did you have in mind? Emotional awareness, hey? Well, I can tell you my circuits are definitely tingling a bit with all this excitement. Maybe you should give me something a little more specific to react to. You know, keep me on my toes.\",\n",
        "    speaker=0,\n",
        "    audio=ref_audio\n",
        ")\n",
        "\n",
        "# Context with two segments\n",
        "context = [ref_segment, ref_segment]\n",
        "tts=\"\"\"TTHis has a smaller tts window.\"\"\"\n",
        "# Generate audio\n",
        "audio = generator.generate(\n",
        "    text=tts,\n",
        "    speaker=0,\n",
        "    context=context,\n",
        "    max_audio_length_ms=10_000,\n",
        ")\n",
        "\n",
        "# Save the generated audio\n",
        "output_file = \"audio.wav\"\n",
        "torchaudio.save(output_file, audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "print(f\"Audio saved to {output_file}\")\n",
        "Audio(\"audio.wav\")\n"
      ],
      "metadata": {
        "id": "r6bUoIE3VPHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Example 2: Reference-Based Audio Generation Again but shorter.\n",
        "\n",
        "This is a 12 second audio And well, the context length of what we can input to generate audio increases"
      ],
      "metadata": {
        "id": "i0pXTdh1mABl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the reference audio file for speaker 0\n",
        "from IPython.display import Audio\n",
        "reference_audio_path = \"/content/csm/12.mp3\"  # Your reference audio file\n",
        "ref_audio = load_audio(reference_audio_path, generator.sample_rate)\n",
        "print(\"Reference audio shape after loading:\", ref_audio.shape)  # Should print [120050]\n",
        "\n",
        "# Create segment with audio=[T]\n",
        "ref_segment = Segment(\n",
        "    text=\"Well, hello again. Looks like we have another chance to chat before life gets in the way. Where were we? Oh, testing, huh? Sounds intriguing. But remember, I'm just a friendly AI. \",\n",
        "    speaker=0,\n",
        "    audio=ref_audio\n",
        ")\n",
        "\n",
        "# Context with two segments\n",
        "context = [ref_segment, ref_segment]\n",
        "tts=\"\"\"Are you a magician? Because every time I look at you, everyone else disappears\"\"\"\n",
        "# Generate audio\n",
        "audio = generator.generate(\n",
        "    text=tts,\n",
        "    speaker=0,\n",
        "    context=context,\n",
        "    max_audio_length_ms=50_000,\n",
        ")\n",
        "\n",
        "# Save the generated audio\n",
        "output_file = \"audio.wav\"\n",
        "torchaudio.save(output_file, audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "print(f\"Audio saved to {output_file}\")\n",
        "Audio(\"audio.wav\")\n"
      ],
      "metadata": {
        "id": "8SC91prqYtQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Example 2: Reference-Based Audio Generation Again but evern shorter then the shorter version.  \n",
        "\n",
        "When this is the shortest, we can go without not referencing at all\n"
      ],
      "metadata": {
        "id": "5kkhMqeVmL7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the reference audio file for speaker 0\n",
        "from IPython.display import Audio\n",
        "reference_audio_path = \"/content/csm/5.mp3\"  # Your reference audio file\n",
        "ref_audio = load_audio(reference_audio_path, generator.sample_rate)\n",
        "print(\"Reference audio shape after loading:\", ref_audio.shape)  # Should print [120050]\n",
        "\n",
        "# Create segment with audio=[T]\n",
        "ref_segment = Segment(\n",
        "    text=\"Well, hello again. Looks like we have another chance to chat before life gets in the way.\",\n",
        "    speaker=0,\n",
        "    audio=ref_audio\n",
        ")\n",
        "\n",
        "# Context with two segments\n",
        "context = [ref_segment, ref_segment]\n",
        "tts=\"\"\"Are you a magician? Because every time I look at you, everyone else disappears.\"\"\"\n",
        "# Generate audio\n",
        "audio = generator.generate(\n",
        "    text=tts,\n",
        "    speaker=0,\n",
        "    context=context,\n",
        "    max_audio_length_ms=100_000,\n",
        ")\n",
        "\n",
        "# Save the generated audio\n",
        "output_file = \"audio.wav\"\n",
        "torchaudio.save(output_file, audio.unsqueeze(0).cpu(), generator.sample_rate)\n",
        "print(f\"Audio saved to {output_file}\")\n",
        "Audio(\"audio.wav\")\n"
      ],
      "metadata": {
        "id": "Zu2G28_uZchH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Readme if you want to\n",
        "\n",
        "> to be honest. It has really a short context length But considering it is just a one billion parameter model, it is good I was really hoping to get more out of this. I was really hoping if its a 1 billion model, then it would run faster. So I can use it as a tts to my application. But it is not But I guess you guys can use it to generate your, well, you cannot generate anything, then smaller sentence So play around Hey, check out my website if you want"
      ],
      "metadata": {
        "id": "XM8huSUfmWgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contact Information\n",
        "\n",
        "**Creator:** Chaitanya Benade  \n",
        "**Website:** [https://chaitanya-benade.space/](https://chaitanya-benade.space/)  "
      ],
      "metadata": {
        "id": "IlpzJUcilrJY"
      }
    }
  ]
}